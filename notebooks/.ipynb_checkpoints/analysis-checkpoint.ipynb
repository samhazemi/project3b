{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import dicom\n",
    "import pydicom\n",
    "import os\n",
    "import seaborn as sns\n",
    "from operator import itemgetter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import gaussian_kde\n",
    "import warnings\n",
    "import plotly \n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train_2016_v2.csv',index_col=False, parse_dates=['transactiondate'])\n",
    "properties_df = pd.read_csv('../data/properties_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meansd=abs(-0.16107794320832886/2+0.011457219606756682) # use this based on exprience to make lowerror number and high error number dont have huge difference.\n",
    "train_df['class'] = pd.cut(abs(train_df.logerror),[0,meansd,1e6],3,\n",
    "                                 labels=['lowerror','higherror']) # this creates a new variable\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.to_csv('train_class_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('train_2016_v2.csv',index_col=False, parse_dates=['transactiondate'])\n",
    "properties_df = pd.read_csv('properties_2016.csv')\n",
    "\n",
    "#train_merge_df = pd.merge(train_df, properties_df, on='parcelid', how='left')\n",
    "train_merge_df = pd.merge(properties_df,train_df, on='parcelid')\n",
    "train_merge_df.to_csv('train_merged_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "meansd=abs(-0.16107794320832886/2+0.011457219606756682)\n",
    "train_df = pd.read_csv('train_class_2016.csv',index_col=False, parse_dates=['transactiondate'])\n",
    "properties_df = pd.read_csv('properties_2016.csv')\n",
    "train_df['plotclass'] = pd.cut(abs(train_df.logerror),[0,meansd,1e6],3,\n",
    "                                 labels=['0','1'])\n",
    "\n",
    "train_merge_df = pd.merge(properties_df,train_df, on='parcelid')\n",
    "train_merge_df.to_csv('train_merged_plotclass_2016.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "duplicatedtrain=train_df[train_df.duplicated(['parcelid'], keep=False)]\n",
    "duplicatedtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(duplicatedtrain['parcelid'].value_counts().describe())\n",
    "print((duplicatedtrain['parcelid'].value_counts()==3).sum())\n",
    "print((duplicatedtrain['parcelid'].value_counts()==2).sum())\n",
    "print(duplicatedtrain['parcelid'].value_counts().head())\n",
    "doubleduplicated=duplicatedtrain[~(duplicatedtrain['parcelid']==11842707)]\n",
    "doubleduplicated1=pd.DataFrame(doubleduplicated['logerror'])\n",
    "errorchange=[]\n",
    "print (doubleduplicated1.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(train_df.logerror.describe())\n",
    "x = train_df.logerror\n",
    "data = [go.Histogram(x=x)]\n",
    "iplot(data, filename='basic histogram of logerror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from plotly.offline import iplot_mpl\n",
    "print(np.mean(train_df.logerror))\n",
    "print(np.std(train_df.logerror))\n",
    "def removeoutlier(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    leave = [i for i in data if (mean - 2 * std < i < mean + 2 * std)]\n",
    "    return leave\n",
    "filtered_d = removeoutlier(train_df.logerror)\n",
    "fig = plt.figure()\n",
    "sns.set_palette(\"hls\")\n",
    "sns.distplot(filtered_d);\n",
    "iplot_mpl(fig,strip_style=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meansd=abs(-0.16107794320832886/2+0.011457219606756682) # use this based on exprience to make lowerror number and high error number dont have huge difference.\n",
    "train_df['class'] = pd.cut(abs(train_df.logerror),[0,meansd,1e6],3,\n",
    "                                 labels=['lowerror','higherror']) # this creates a new variable\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "properties_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(properties_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "properties_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "null_count=pd.DataFrame(properties_df.isnull().sum())\n",
    "null_count.columns=['nullnumber']\n",
    "sortednull=null_count.sort_values(by='nullnumber')\n",
    "data = [go.Bar(\n",
    "            x=sortednull.index,\n",
    "            y=sortednull.nullnumber\n",
    "    )]\n",
    "\n",
    "iplot(data, filename='basic-bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(properties_df.shape)\n",
    "nullpercent=sortednull\n",
    "nullpercent.columns=['Null percent']\n",
    "print(nullpercent[:31]/2985217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "properties_df[['rawcensustractandblock','censustractandblock']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(properties_df['rawcensustractandblock'], properties_df['censustractandblock'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "properties_df[properties_df.duplicated(['parcelid'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "properties_df[['rawcensustractandblock','regionidcounty','longitude','latitude','regionidzip','regionidcity','regionidneighborhood']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "mergelogerror_properties = pd.merge(properties_df,train_df, on='parcelid')\n",
    "%matplotlib inline \n",
    "locationproperties=mergelogerror_properties[['longitude','latitude','regionidzip','regionidcity','regionidneighborhood','class']].sample(5000)\n",
    "locationproperties['longitude']=locationproperties.longitude/1e6\n",
    "locationproperties['latitude']=locationproperties.latitude/1e6\n",
    "locationproperties1=locationproperties.dropna()\n",
    "sns.pairplot(locationproperties1,diag_kind=\"kde\",hue=\"class\",markers='+',plot_kws=dict(s=1,edgecolor=\"g\", linewidth=1),diag_kws=dict(shade=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=mergelogerror_properties.latitude.values/1e6\n",
    "x=mergelogerror_properties.longitude.values/1e6\n",
    "xy = np.vstack([x,y])\n",
    "z = gaussian_kde(xy)(xy)# Calculate the point density\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y, c=z, s=100, edgecolor='')\n",
    "ax.set_xlabel('longtitude')\n",
    "ax.set_ylabel('latitude')\n",
    "plt.title('Properties Density Distrbution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structioncondition=mergelogerror_properties[['parcelid','bedroomcnt','bathroomcnt','roomcnt','fullbathcnt','calculatedbathnbr','unitcnt','buildingqualitytypeid','heatingorsystemtypeid','logerror','class']]\n",
    "structioncondition['lowerror']=[0 if i!='lowerror' else 1 for i in structioncondition['class']]\n",
    "\n",
    "\n",
    "errorgroup = pd.crosstab([structioncondition['heatingorsystemtypeid'],\n",
    "                    structioncondition['buildingqualitytypeid']], \n",
    "                    structioncondition['class'])\n",
    "print(errorgroup)\n",
    "\n",
    "error_rate = errorgroup.div(errorgroup.sum(1).astype(float),\n",
    "                             axis=0) \n",
    "\n",
    "\n",
    "error_rate.plot(kind='barh', \n",
    "                   stacked=True)\n",
    "plt.title('lowerror and high error percentage by heating system type and building quality type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "structioncondition=mergelogerror_properties[['parcelid','bedroomcnt','bathroomcnt','roomcnt','fullbathcnt','calculatedbathnbr','unitcnt','buildingqualitytypeid','heatingorsystemtypeid','logerror','class']]\n",
    "structioncondition['lowerror']=[0 if i!='lowerror' else 1 for i in structioncondition['class']]\n",
    "structionconditionnumber=structioncondition[['buildingqualitytypeid','bedroomcnt','bathroomcnt','roomcnt','fullbathcnt','calculatedbathnbr','unitcnt']]\n",
    "structionconditionnumber.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cmap = sns.diverging_palette(220, 10, as_cmap=True) \n",
    "sns.set(style=\"white\") \n",
    "f, ax = plt.subplots(figsize=(9, 9))\n",
    "sns.heatmap(structioncondition[['bedroomcnt','bathroomcnt','roomcnt','fullbathcnt','calculatedbathnbr','unitcnt','buildingqualitytypeid','heatingorsystemtypeid','logerror']].corr(), cmap=cmap, annot=True)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeproperties=mergelogerror_properties[['yearbuilt','assessmentyear','logerror','class']]\n",
    "timeproperties.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logerrortimemean=timeproperties[['logerror','yearbuilt']].groupby('yearbuilt'). mean()\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "plotly.offline.iplot({\n",
    "    \"data\": [{\n",
    "        \"x\": logerrortimemean.index,\n",
    "        \"y\": logerrortimemean.logerror\n",
    "    }],\n",
    "    \"layout\": {\n",
    "        \"title\": \"Mean of logerror VS Built year\"\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "timeproperties=timeproperties[['yearbuilt','logerror','class']]\n",
    "sns.distplot(properties_df.yearbuilt[~np.isnan(properties_df.yearbuilt)])\n",
    "plt.title('Distribution of parcels with builtyear ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "train_df['month']=train_df['transactiondate'].dt.month\n",
    "plt.hist(train_df['month'],bins=12)\n",
    "plt.title('hist of number of transactions in every month in 2016 ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainlogerrormean=train_df[['logerror','month']].groupby('month'). mean()\n",
    "plotly.offline.init_notebook_mode() \n",
    "plotly.offline.iplot({\n",
    "    \"data\": [{\n",
    "        \"x\": [1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "        \"y\": trainlogerrormean.logerror\n",
    "    }],\n",
    "    \"layout\": {\n",
    "        \"title\": \"Mean of logerror VS Transaction Month\"\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstrain_2016=train_df\n",
    "abstrain_2016['logerror']=abs(train_df['logerror'])\n",
    "abstrain_2016mean=abstrain_2016[['logerror','month']].groupby('month'). mean()\n",
    "plotly.offline.init_notebook_mode() # run at the start of every notebook\n",
    "plotly.offline.iplot({\n",
    "    \"data\": [{\n",
    "        \"x\": [1,2,3,4,5,6,7,8,9,10,11,12],\n",
    "        \"y\": abstrain_2016mean.logerror\n",
    "    }],\n",
    "    \"layout\": {\n",
    "        \"title\": \"Mean of Abs(logerror) VS Transaction Month\"\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mergelogerror_properties['month']=mergelogerror_properties['transactiondate'].dt.month\n",
    "sns.violinplot(x=\"month\", y=\"yearbuilt\", hue=\"class\", data=mergelogerror_properties,\n",
    "               split=True, inner=\"quart\")\n",
    "plt.title('Violion plot of logerror by built year and transaction month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "areapropertyland=mergelogerror_properties[['parcelid','calculatedfinishedsquarefeet','finishedsquarefeet12','lotsizesquarefeet','taxamount','taxvaluedollarcnt','structuretaxvaluedollarcnt','propertycountylandusecode','propertyzoningdesc','landtaxvaluedollarcnt','logerror','class']]\n",
    "areapropertyland.describe()\n",
    "\n",
    "%matplotlib inline \n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True) \n",
    "sns.set(style=\"darkgrid\") \n",
    "f, ax = plt.subplots(figsize=(9, 9))\n",
    "sns.heatmap(areapropertyland[['calculatedfinishedsquarefeet','finishedsquarefeet12','lotsizesquarefeet','taxamount','taxvaluedollarcnt','structuretaxvaluedollarcnt','propertycountylandusecode','propertyzoningdesc','landtaxvaluedollarcnt','logerror']].corr(), cmap=cmap, annot=True)\n",
    "plt.title('Correlation Matrix Graph')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition.pca import PCA\n",
    "from sklearn import preprocessing\n",
    "df=mergelogerror_properties[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','yearbuilt','taxamount','lotsizesquarefeet','logerror']].copy()\n",
    "df=df.dropna()\n",
    "df_scaled = preprocessing.scale(df[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','yearbuilt','taxamount','lotsizesquarefeet']])\n",
    "df_scaled=pd.DataFrame(df_scaled)\n",
    "df_scaled.columns=[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','yearbuilt','taxamount','lotsizesquarefeet']]\n",
    "\n",
    "print(df_scaled.head())\n",
    "y = df.logerror\n",
    "target_names='logerror'\n",
    "\n",
    "\n",
    " \n",
    "for k in range(1,6):\n",
    "    pca=PCA(n_components=k)\n",
    "    X_pca = pca.fit(df_scaled).transform(df_scaled)\n",
    "    pca.fit(df_scaled)\n",
    "    print('explained_variance_ratio:',pca.explained_variance_ratio_)\n",
    "    print('pca:',pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\n",
    "import plotly.tools as tls\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X=df_scaled\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "\n",
    "\n",
    "cov_mat = np.cov(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "cor_mat1 = np.corrcoef(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat1)\n",
    "\n",
    "cor_mat2 = np.corrcoef(X.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "\n",
    "u,s,v = np.linalg.svd(X_std.T)\n",
    "for ev in eig_vecs:\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "\n",
    "\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "\n",
    "\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])\n",
    "\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('the cum')\n",
    "print(cum_var_exp)\n",
    "trace1 = Bar(\n",
    "        x=['PC %s' %i for i in range(1,5)],\n",
    "        y=var_exp,\n",
    "        showlegend=False)\n",
    "\n",
    "trace2 = Scatter(\n",
    "        x=['PC %s' %i for i in range(1,5)], \n",
    "        y=cum_var_exp,\n",
    "        name='cumulative explained variance')\n",
    "\n",
    "data1 = Data([trace1, trace2])\n",
    "\n",
    "layout=Layout(\n",
    "        yaxis=YAxis(title='Explained variance in percent'),\n",
    "        title='Number of rooms variables: Explained variance by different principal components ')\n",
    "\n",
    "fig = Figure(data=data1, layout=layout)\n",
    "py.iplot(Figure(data=data1, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df_scaled[['fullbathcnt','buildingqualitytypeid','heatingorsystemtypeid','taxamount','lotsizesquarefeet']]\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "cov_mat = np.cov(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "cor_mat1 = np.corrcoef(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat1)\n",
    "cor_mat2 = np.corrcoef(X.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "u,s,v = np.linalg.svd(X_std.T)\n",
    "for ev in eig_vecs:\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "\n",
    "\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])\n",
    "\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('the cum')\n",
    "print(cum_var_exp)\n",
    "trace1 = Bar(\n",
    "        x=['PC %s' %i for i in range(1,5)],\n",
    "        y=var_exp,\n",
    "        showlegend=False)\n",
    "\n",
    "trace2 = Scatter(\n",
    "        x=['PC %s' %i for i in range(1,5)], \n",
    "        y=cum_var_exp,\n",
    "        name='cumulative explained variance')\n",
    "\n",
    "data1 = Data([trace1, trace2])\n",
    "\n",
    "layout=Layout(\n",
    "        yaxis=YAxis(title='Explained variance in percent'),\n",
    "        title='Number of rooms variables: Explained variance by different principal components ')\n",
    "\n",
    "#fig = Figure(data=data1, layout=layout)\n",
    "#py.iplot(Figure(data=data1, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "meansd=abs(-0.16107794320832886/2+0.011457219606756682)\n",
    "train_df['plotclass'] = pd.cut(abs(train_df.logerror),[0,meansd,1e6],3,\n",
    "                                 labels=['0','1']) # this creates a new variable\n",
    "mergelogerror_properties = pd.merge(properties_df,train_df, on='parcelid')\n",
    "df=mergelogerror_properties[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','yearbuilt','taxamount','lotsizesquarefeet','logerror','plotclass']].sample(1000).copy()\n",
    "df=df.dropna()\n",
    "df_scaled = preprocessing.scale(df[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','taxamount','lotsizesquarefeet']])\n",
    "df_scaled=pd.DataFrame(df_scaled)\n",
    "df_scaled.columns=[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','taxamount','lotsizesquarefeet']]\n",
    "\n",
    "y=df.plotclass\n",
    "\n",
    "target_names='logerror'\n",
    " # fit data and then transform it\n",
    "for k in range(1,6):\n",
    "    pca=PCA(n_components=k)\n",
    "    X_pca = pca.fit(df_scaled).transform(df_scaled)\n",
    "    pca.fit(df_scaled)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_feature_names_from_weights(weights, names):\n",
    "    tmp_array = []\n",
    "    for comp in weights:\n",
    "        tmp_string = ''\n",
    "        for fidx,f in enumerate(names):\n",
    "            if fidx>0 and comp[fidx]>=0:\n",
    "                tmp_string+='+'\n",
    "            tmp_string += '%.2f*%s ' % (comp[fidx],f[:-5])\n",
    "        tmp_array.append(tmp_string)\n",
    "    return tmp_array\n",
    "  \n",
    "pca_weight_strings = get_feature_names_from_weights(pca.components_, df_scaled.columns) \n",
    "df_pca = pd.DataFrame(X_pca,columns=[pca_weight_strings])\n",
    "y=preprocessing.scale(y)\n",
    "ax = scatter_plot(df_pca, pca_weight_strings[0], pca_weight_strings[1], c=y,s=(y+2)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
