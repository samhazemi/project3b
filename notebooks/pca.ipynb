{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#import dicom\n",
    "import pydicom\n",
    "import os\n",
    "import seaborn as sns\n",
    "from operator import itemgetter\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import gaussian_kde\n",
    "import warnings\n",
    "import plotly \n",
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import numpy as np\n",
    "#import plotly.plotly as py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train_2016_v2.csv',index_col=False, parse_dates=['transactiondate'])\n",
    "#properties_df = pd.read_csv('../data/properties_2016.csv')\n",
    "mergelogerror_properties=pd.read_csv('../data/train_merged_class_2016.csv')  \n",
    "mergelogerror_properties_plotclass=pd.read_csv('../data/train_merged_plotclass_2016.csv') \n",
    "mergelogerror_properties_plotclass.head()    \n",
    "mergelogerror_properties_plotclass.describe()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatedtrain=train_df[train_df.duplicated(['parcelid'], keep=False)]\n",
    "duplicatedtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(duplicatedtrain['parcelid'].value_counts().describe())\n",
    "print((duplicatedtrain['parcelid'].value_counts()==3).sum())\n",
    "print((duplicatedtrain['parcelid'].value_counts()==2).sum())\n",
    "print(duplicatedtrain['parcelid'].value_counts().head())\n",
    "doubleduplicated=duplicatedtrain[~(duplicatedtrain['parcelid']==11842707)]\n",
    "doubleduplicated1=pd.DataFrame(doubleduplicated['logerror'])\n",
    "errorchange=[]\n",
    "print (doubleduplicated1.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import numpy as np\n",
    "print(train_df.logerror.describe())\n",
    "x = train_df.logerror\n",
    "#data = [go.Histogram(x=x)]\n",
    "#iplot(data, filename='basic histogram of logerror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "#mergelogerror_properties = pd.merge(properties_df,train_df, on='parcelid')\n",
    "#%matplotlib inline \n",
    "locationproperties=mergelogerror_properties[['longitude','latitude','regionidzip','regionidcity','regionidneighborhood','class']].sample(5000)\n",
    "locationproperties['longitude']=locationproperties.longitude/1e6\n",
    "locationproperties['latitude']=locationproperties.latitude/1e6\n",
    "locationproperties1=locationproperties.dropna()\n",
    "sns.pairplot(locationproperties1,diag_kind=\"kde\",hue=\"class\",markers='+',plot_kws=dict(s=1,edgecolor=\"g\", linewidth=1),diag_kws=dict(shade=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.graph_objs import Scatter, Marker, Layout, XAxis, YAxis\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "#import plotly.plotly as py\n",
    "sample1=mergelogerror_properties.sample(5000)\n",
    "lowerror1 = sample1[(sample1['class'] =='lowerror')]\n",
    "higherror1 = sample1[(sample1['class']=='higherror')]\n",
    "\n",
    "trace_comp0 = go.Scatter(\n",
    "    y=lowerror1.latitude/1e6,\n",
    "    x=lowerror1.longitude/1e6,\n",
    "    mode='markers',\n",
    "    marker=Marker(size=lowerror1.logerror, sizemode='area', sizeref=0.01,color='navy'),\n",
    "    name='lowerror',\n",
    "    text=lowerror1.logerror,\n",
    "    )\n",
    "\n",
    "trace_comp1 = go.Scatter(\n",
    "    y=higherror1.latitude/1e6,\n",
    "    x=higherror1.longitude/1e6,\n",
    "    mode='markers',\n",
    "    marker=Marker(size=higherror1.logerror, sizemode='area', sizeref=0.01,color='red'),\n",
    "    name='higherror',\n",
    "    text=higherror1.logerror,\n",
    "        )\n",
    "\n",
    "data_comp = [trace_comp0, trace_comp1]\n",
    "layout_comp = go.Layout(\n",
    "    title='Location VS logerror',\n",
    "    hovermode='closest',\n",
    "    xaxis=dict(\n",
    "        title='longitude)',\n",
    "        ticklen=5,\n",
    "        zeroline=False,\n",
    "        gridwidth=2,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='latitude',\n",
    "        ticklen=5,\n",
    "        gridwidth=2,\n",
    "    ),\n",
    ")\n",
    "fig_comp = go.Figure(data=data_comp, layout=layout_comp)\n",
    "iplot(fig_comp, filename='location vs logerror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structioncondition=mergelogerror_properties[['parcelid','bedroomcnt','bathroomcnt','roomcnt','fullbathcnt','calculatedbathnbr','unitcnt','buildingqualitytypeid','heatingorsystemtypeid','logerror','class']]\n",
    "structioncondition['lowerror']=[0 if i!='lowerror' else 1 for i in structioncondition['class']]\n",
    "\n",
    "#print(structioncondition['class'])\n",
    "errorgroup = pd.crosstab([structioncondition['heatingorsystemtypeid'],\n",
    "                    structioncondition['buildingqualitytypeid']], \n",
    "                    structioncondition['class'])\n",
    "print(errorgroup)\n",
    "#errorgroup.plot(kind='bar', stacked=True)\n",
    "error_rate = errorgroup.div(errorgroup.sum(1).astype(float),\n",
    "                             axis=0) # normalize the value\n",
    "\n",
    "# print survival_rate\n",
    "error_rate.plot(kind='barh', \n",
    "                   stacked=True)\n",
    "plt.title('lowerror and high error percentage by heating system type and building quality type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structioncondition=mergelogerror_properties[['parcelid','bedroomcnt','bathroomcnt','roomcnt','fullbathcnt','calculatedbathnbr','unitcnt','buildingqualitytypeid','heatingorsystemtypeid','logerror','class']]\n",
    "structioncondition['lowerror']=[0 if i!='lowerror' else 1 for i in structioncondition['class']]\n",
    "structionconditionnumber=structioncondition[['buildingqualitytypeid','bedroomcnt','bathroomcnt','roomcnt','fullbathcnt','calculatedbathnbr','unitcnt']]\n",
    "structionconditionnumber.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeproperties=mergelogerror_properties[['yearbuilt','assessmentyear','logerror','class']]\n",
    "timeproperties.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logerrortimemean=timeproperties[['logerror','yearbuilt']].groupby('yearbuilt'). mean()\n",
    "logerrortimemean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeproperties=timeproperties[['yearbuilt','logerror','class']]\n",
    "timeproperties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['month']=train_df['transactiondate'].dt.month\n",
    "train_df['month'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlogerrormean=train_df[['logerror','month']].groupby('month'). mean()\n",
    "trainlogerrormean.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstrain_2016=train_df\n",
    "abstrain_2016['logerror']=abs(train_df['logerror'])\n",
    "abstrain_2016mean=abstrain_2016[['logerror','month']].groupby('month'). mean()\n",
    "abstrain_2016mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mergelogerror_properties['month']=mergelogerror_properties['transactiondate'].dt.month\n",
    "mergelogerror_properties['transactiondate'] = pd.to_datetime(mergelogerror_properties['transactiondate'], errors='coerce')\n",
    "mergelogerror_properties['month']=mergelogerror_properties['transactiondate'].dt.month\n",
    "#mergelogerror_properties['transactiondate'][0]\n",
    "mergelogerror_properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "areapropertyland=mergelogerror_properties[['parcelid','calculatedfinishedsquarefeet','finishedsquarefeet12','lotsizesquarefeet','taxamount','taxvaluedollarcnt','structuretaxvaluedollarcnt','propertycountylandusecode','propertyzoningdesc','landtaxvaluedollarcnt','logerror','class']]\n",
    "areapropertyland.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition.pca import PCA\n",
    "from sklearn import preprocessing\n",
    "df=mergelogerror_properties[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','yearbuilt','taxamount','lotsizesquarefeet','logerror']].copy()\n",
    "df=df.dropna()\n",
    "df_scaled = preprocessing.scale(df[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','yearbuilt','taxamount','lotsizesquarefeet']])\n",
    "df_scaled=pd.DataFrame(df_scaled)\n",
    "df_scaled.columns=[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','yearbuilt','taxamount','lotsizesquarefeet']]\n",
    "\n",
    "print(df_scaled.head())\n",
    "y = df.logerror\n",
    "target_names='logerror'\n",
    "\n",
    "\n",
    " # fit data and then transform it\n",
    "for k in range(1,6):\n",
    "    pca=PCA(n_components=k)\n",
    "    X_pca = pca.fit(df_scaled).transform(df_scaled)\n",
    "    pca.fit(df_scaled)\n",
    "    print('explained_variance_ratio:',pca.explained_variance_ratio_)\n",
    "    print('pca:',pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\n",
    "import plotly.tools as tls\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X=df_scaled\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "#print('Covariance matrix \\n%s' %cov_mat)\n",
    "#print('NumPy covariance matrix: \\n%s' %np.cov(X_std.T))\n",
    "cov_mat = np.cov(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "cor_mat1 = np.corrcoef(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat1)\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "cor_mat2 = np.corrcoef(X.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "#u,s,v = np.linalg.svd(X_std.T)\n",
    "for ev in eig_vecs:\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])\n",
    "\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('the cum')\n",
    "print(cum_var_exp)\n",
    "\n",
    "\n",
    "#fig = Figure(data=data1, layout=layout)\n",
    "#iplot(Figure(data=data1, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "trace1 = go.Bar(\n",
    "        x=['PC %s' %i for i in range(1,5)],\n",
    "        y=var_exp,\n",
    "#    ,\n",
    "        showlegend=False)\n",
    "\n",
    "trace2 = Scatter(\n",
    "        x=['PC %s' %i for i in range(1,5)], \n",
    "        y=cum_var_exp,\n",
    "        name='cumulative explained variance')\n",
    "\n",
    "data1 = Data([trace1, trace2])\n",
    "\n",
    "layout=Layout(\n",
    "        yaxis=YAxis(title='Explained variance in percent'),\n",
    "        title='Number of rooms variables: Explained variance by different principal components ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trace1 = go.Bar(\n",
    "        x=['PC %s' %i for i in range(1,5)],\n",
    "        y=var_exp,\n",
    "        showlegend=False)\n",
    "\n",
    "trace2 = Scatter(\n",
    "        x=['PC %s' %i for i in range(1,5)], \n",
    "        y=cum_var_exp,\n",
    "        name='cumulative explained variance')\n",
    "\n",
    "data1 = Data([trace1, trace2])\n",
    "\n",
    "layout=Layout(\n",
    "        yaxis=YAxis(title='Explained variance in percent'),\n",
    "        title='Number of rooms variables: Explained variance by different principal components ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X=df_scaled[['fullbathcnt','buildingqualitytypeid','heatingorsystemtypeid','taxamount','lotsizesquarefeet']]\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "#print('Covariance matrix \\n%s' %cov_mat)\n",
    "#print('NumPy covariance matrix: \\n%s' %np.cov(X_std.T))\n",
    "cov_mat = np.cov(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "cor_mat1 = np.corrcoef(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat1)\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "cor_mat2 = np.corrcoef(X.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "#u,s,v = np.linalg.svd(X_std.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import plotly.plotly as py\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\n",
    "for ev in eig_vecs:\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "\n",
    "\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])\n",
    "\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('the cum')\n",
    "print(cum_var_exp)\n",
    "trace1 = go.Bar(\n",
    "        x=['PC %s' %i for i in range(1,5)],\n",
    "        y=var_exp,\n",
    "        showlegend=False)\n",
    "\n",
    "trace2 = Scatter(\n",
    "        x=['PC %s' %i for i in range(1,5)], \n",
    "        y=cum_var_exp,\n",
    "        name='cumulative explained variance')\n",
    "\n",
    "data1 = Data([trace1, trace2])\n",
    "\n",
    "layout=Layout(\n",
    "        yaxis=YAxis(title='Explained variance in percent'),\n",
    "        title='Number of rooms variables: Explained variance by different principal components ')\n",
    "\n",
    "fig = Figure(data=data1, layout=layout)\n",
    "iplot(Figure(data=data1, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot,iplot\n",
    "X=df_scaled[['fullbathcnt','buildingqualitytypeid','heatingorsystemtypeid','taxamount','lotsizesquarefeet']]\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "mean_vec = np.mean(X_std, axis=0)\n",
    "cov_mat = (X_std - mean_vec).T.dot((X_std - mean_vec)) / (X_std.shape[0]-1)\n",
    "#print('Covariance matrix \\n%s' %cov_mat)\n",
    "#print('NumPy covariance matrix: \\n%s' %np.cov(X_std.T))\n",
    "cov_mat = np.cov(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "cor_mat1 = np.corrcoef(X_std.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat1)\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "cor_mat2 = np.corrcoef(X.T)\n",
    "eig_vals, eig_vecs = np.linalg.eig(cor_mat2)\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)\n",
    "#u,s,v = np.linalg.svd(X_std.T)\n",
    "for ev in eig_vecs:\n",
    "    np.testing.assert_array_almost_equal(1.0, np.linalg.norm(ev))\n",
    "# Make a list of (eigenvalue, eigenvector) tuples\n",
    "\n",
    "eig_pairs = [(np.abs(eig_vals[i]), eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "\n",
    "# Sort the (eigenvalue, eigenvector) tuples from high to low\n",
    "eig_pairs.sort()\n",
    "eig_pairs.reverse()\n",
    "\n",
    "# Visually confirm that the list is correctly sorted by decreasing eigenvalues\n",
    "print('Eigenvalues in descending order:')\n",
    "for i in eig_pairs:\n",
    "    print(i[0])\n",
    "\n",
    "tot = sum(eig_vals)\n",
    "var_exp = [(i / tot)*100 for i in sorted(eig_vals, reverse=True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "print('the cum')\n",
    "print(cum_var_exp)\n",
    "trace1 = go.Bar(\n",
    "        x=['PC %s' %i for i in range(1,5)],\n",
    "        y=var_exp,\n",
    "        showlegend=False)\n",
    "\n",
    "trace2 = Scatter(\n",
    "        x=['PC %s' %i for i in range(1,5)], \n",
    "        y=cum_var_exp,\n",
    "        name='cumulative explained variance')\n",
    "\n",
    "data1 = Data([trace1, trace2])\n",
    "\n",
    "layout=Layout(\n",
    "        yaxis=YAxis(title='Explained variance in percent'),\n",
    "        title='Number of rooms variables: Explained variance by different principal components ')\n",
    "\n",
    "fig = Figure(data=data1, layout=layout)\n",
    "iplot(Figure(data=data1, layout=layout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mergelogerror_properties_plotclass['yearbuilt'] = pd.to_datetime(mergelogerror_properties_plotclass['yearbuilt'], errors='coerce')\n",
    "type(mergelogerror_properties_plotclass['yearbuilt'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#meansd=abs(-0.16107794320832886/2+0.011457219606756682)\n",
    "#train_df['plotclass'] = pd.cut(abs(train_df.logerror),[0,meansd,1e6],3,\n",
    "#                                 labels=['0','1']) # this creates a new variable\n",
    "#mergelogerror_properties_plotclass = pd.merge(properties_df,train_df, on='parcelid')\n",
    "df=mergelogerror_properties_plotclass[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','yearbuilt','taxamount','lotsizesquarefeet','logerror','plotclass']].sample(1000).copy()\n",
    "df=df.dropna()\n",
    "df_scaled = preprocessing.scale(df[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','taxamount','lotsizesquarefeet']])\n",
    "df_scaled=pd.DataFrame(df_scaled)\n",
    "df_scaled.columns=[['longitude','latitude','fullbathcnt','calculatedbathnbr','buildingqualitytypeid','heatingorsystemtypeid','taxamount','lotsizesquarefeet']]\n",
    "#print(df.plotclass.describe())\n",
    "y=df.plotclass\n",
    "\n",
    "target_names='logerror'\n",
    " # fit data and then transform it\n",
    "for k in range(1,6):\n",
    "    pca=PCA(n_components=k)\n",
    "    X_pca = pca.fit(df_scaled).transform(df_scaled)\n",
    "    pca.fit(df_scaled)\n",
    "    #print('explained_variance_ratio:',pca.explained_variance_ratio_)\n",
    "    #print('pca:',pca.components_)\n",
    "    from pandas.plotting import scatter_matrix\n",
    "def get_feature_names_from_weights(weights, names):\n",
    "    tmp_array = []\n",
    "    for comp in weights:\n",
    "        tmp_string = ''\n",
    "        for fidx,f in enumerate(names):\n",
    "            if fidx>0 and comp[fidx]>=0:\n",
    "                tmp_string+='+'\n",
    "            tmp_string += '%.2f*%s ' % (comp[fidx],f[:-5])\n",
    "        tmp_array.append(tmp_string)\n",
    "    return tmp_array\n",
    "  \n",
    "pca_weight_strings = get_feature_names_from_weights(pca.components_, df_scaled.columns) \n",
    "df_pca = pd.DataFrame(X_pca,columns=[pca_weight_strings])\n",
    "y=preprocessing.scale(y)\n",
    "ax = scatter_matrix(df_pca, pca_weight_strings[0], pca_weight_strings[1], c=y,s=(y+2)*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_weight_strings[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition.pca import PCA\n",
    "from sklearn import preprocessing\n",
    "df=mergelogerror_properties_plotclass[['bedroomcnt','bathroomcnt','fullbathcnt','calculatedbathnbr','unitcnt','plotclass']].copy()\n",
    "df=df.dropna()\n",
    "df_scaled = preprocessing.scale(df[['bedroomcnt','bathroomcnt','fullbathcnt','calculatedbathnbr','unitcnt']])\n",
    "df_scaled=pd.DataFrame(df_scaled)\n",
    "df_scaled.columns=[['bedroomcnt','bathroomcnt','fullbathcnt','calculatedbathnbr','unitcnt']]\n",
    "\n",
    "print(df_scaled.head())\n",
    "y = df.plotclass\n",
    "target_names='plotclass'\n",
    "\n",
    "for k in range(1,3):\n",
    "    pca=PCA(n_components=k)\n",
    "    X_pca = pca.fit(df_scaled).transform(df_scaled)\n",
    "    pca.fit(df_scaled)\n",
    "    print('explained_variance_ratio:',pca.explained_variance_ratio_)\n",
    "    print('pca:',pca.components_)\n",
    "\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "def get_feature_names_from_weights(weights, names):\n",
    "    tmp_array = []\n",
    "    for comp in weights:\n",
    "        tmp_string = ''\n",
    "        for fidx,f in enumerate(names):\n",
    "            if fidx>0 and comp[fidx]>=0:\n",
    "                tmp_string+='+'\n",
    "            tmp_string += '%.2f*%s ' % (comp[fidx],f[:-5])\n",
    "        tmp_array.append(tmp_string)\n",
    "    return tmp_array\n",
    "  \n",
    "pca_weight_strings = get_feature_names_from_weights(pca.components_, df_scaled.columns) \n",
    "df_pca = pd.DataFrame(X_pca,columns=[pca_weight_strings])\n",
    "y=preprocessing.scale(y)\n",
    "ax = scatter_matrix(df_pca, pca_weight_strings[0], pca_weight_strings[1], c=y,s=(y+2)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
